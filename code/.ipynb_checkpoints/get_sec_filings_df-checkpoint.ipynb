{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import edgar\n",
    "import os\n",
    "from pathlib2 import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate df with all companies and URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_project_dir():\n",
    "    try:\n",
    "        project_dir = Path.cwd() / '/' / 'My Drive' / 'Jotham' / 'Personal Docs' / 'ML for finance' / 'SEC Sentiment Analysis' / 'sec-sentiment'\n",
    "        os.chdir(project_dir)\n",
    "    except BaseException as e:\n",
    "        project_dir = Path.cwd() / '/' / 'Volumes' / 'GoogleDrive' / 'My Drive' / 'Jotham' / 'Personal Docs' / 'ML for finance' / 'SEC Sentiment Analysis' / 'sec-sentiment'\n",
    "        os.chdir(project_dir)\n",
    "    return project_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(get_project_dir(), 'sec-filings-index'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filing_year = 2013   # choose year to get filings from\n",
    "# edgar.download_index(os.getcwd(), filing_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get list of all DFs \n",
    "table_list = []\n",
    "\n",
    "for i in os.listdir():\n",
    "    if i.endswith('.tsv'):\n",
    "        table_list.append(pd.read_csv(i, sep='|', header=None, encoding='latin-1', parse_dates=[3], dtype={0: int}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# append all dfs into a single df\n",
    "\n",
    "df = pd.DataFrame(columns=[0,1,2,3,4,5])   # downloaded file has 6 columns\n",
    "\n",
    "for i in range(len(table_list)):\n",
    "        df = pd.concat([df, table_list[i]], ignore_index=True, axis=0)\n",
    "\n",
    "df.columns= ['cik', 'company_name', 'filing_type', 'filing_date', 'url', 'url2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if dataframe correctly generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df tallies with individual files. Total rows = 6061186\n"
     ]
    }
   ],
   "source": [
    "count_list = []\n",
    "for i in range(len(table_list)):\n",
    "    count_list.append(len(table_list[i]))\n",
    "\n",
    "if df.shape[0] == sum(count_list):\n",
    "    print('df tallies with individual files. Total rows = {}'.format(df.shape[0]))\n",
    "else:\n",
    "    print('ERROR. df does not tally!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download_filings(cik_num_list, from_date='2014-01-01'):\n",
    "    \"\"\"Function to filter the appropriate filings and download them in the folder\"\"\"\n",
    "    \n",
    "    # filter df with company CIK,filing type (10-K and 10-Q) and date  \n",
    "    df_filtered = df [(df['cik'].isin(cik_num_list)) & \n",
    "                      ((df['filing_type']=='10-K') | (df['filing_type'] == '10-Q')) & \n",
    "                      (df['filing_date'] > from_date)]\n",
    "    \n",
    "    company_names = df_filtered['company_name'].unique().tolist()\n",
    "    \n",
    "    # check if folders for each company already exists    \n",
    "    sec_filings_dir = os.path.join(get_project_dir(), 'sec-filings-downloaded')  # dir to download SEC filingsa\n",
    "    os.chdir(sec_filings_dir)\n",
    "\n",
    "    for company in company_names:\n",
    "        company_dir = os.path.join(sec_filings_dir, company)\n",
    "\n",
    "        if not os.path.exists(company_dir):\n",
    "            os.makedirs(company_dir)\n",
    "            print('\\n created dir: {}'.format(company))\n",
    "        else:\n",
    "            print('\\n{} directory exists'.format(company))\n",
    "            \n",
    "        os.chdir(company_dir)\n",
    "        \n",
    "        # create company specific df to iterate over    \n",
    "        df_filtered_co = df_filtered[df_filtered['company_name'] == company]  # get df with the company only\n",
    "        df_filtered_co['filing_date'] = df_filtered_co['filing_date'].astype(str)   # convert to 'object' to name file\n",
    "\n",
    "        for i in range(len(df_filtered_co)):\n",
    "            url_prefix = 'https://www.sec.gov/Archives/'\n",
    "            row = df_filtered_co.iloc[i,:]\n",
    "            url = url_prefix + row['url']\n",
    "            response = requests.get(url, stream=True)\n",
    "            \n",
    "            filing_name = row['filing_date'] + str('_') + row['filing_type']\n",
    "            if os.path.isfile(filing_name):\n",
    "                print('{} file already exists'.format(filing_name))\n",
    "            else:\n",
    "                print('Downloading: {}'.format(filing_name))\n",
    "                with open('{}'.format(filing_name), 'wb') as handle:\n",
    "                    for data in tqdm(response.iter_content()):\n",
    "                        handle.write(data)\n",
    "                        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NICHOLAS FINANCIAL INC directory exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jotham\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-14_10-Q file already exists\n",
      "2019-02-14_10-Q file already exists\n",
      "2018-02-09_10-Q file already exists\n",
      "2018-11-14_10-Q file already exists\n",
      "2017-08-09_10-Q file already exists\n",
      "2018-06-27_10-K file already exists\n",
      "2017-11-09_10-Q file already exists\n",
      "2017-06-14_10-K file already exists\n",
      "2016-11-09_10-Q file already exists\n",
      "2017-02-09_10-Q file already exists\n",
      "2016-08-09_10-Q file already exists\n",
      "2016-06-14_10-K file already exists\n",
      "2015-08-10_10-Q file already exists\n",
      "2015-11-09_10-Q file already exists\n",
      "2016-02-09_10-Q file already exists\n",
      "2015-06-15_10-K file already exists\n",
      "2015-02-09_10-Q file already exists\n",
      "2014-08-11_10-Q file already exists\n",
      "2014-11-10_10-Q file already exists\n",
      "2014-06-16_10-K file already exists\n",
      "2014-02-10_10-Q file already exists\n",
      "\n",
      "CORE LABORATORIES N V directory exists\n",
      "2018-07-27_10-Q file already exists\n",
      "2019-02-11_10-K file already exists\n",
      "Downloading: 2018-02-12_10-K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "908958it [00:06, 130814.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 2018-10-25_10-Q\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "407635it [00:03, 124641.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 2017-07-26_10-Q\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "959519it [00:06, 144148.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 2018-04-27_10-Q\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "370597it [00:02, 126365.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 2017-10-25_10-Q\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369063it [00:05, 67399.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 2017-04-21_10-Q\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "332111it [00:07, 45100.43it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 2016-10-21_10-Q\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "972655it [00:41, 23399.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 2017-02-10_10-K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "939804it [00:13, 68090.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 2016-07-22_10-Q\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "970152it [00:05, 183919.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 2016-04-22_10-Q\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "920922it [00:05, 172573.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 2015-07-27_10-Q\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "955715it [00:06, 159174.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 2015-10-23_10-Q\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "958585it [00:05, 163622.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 2016-02-12_10-K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2147768it [00:31, 67839.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 2015-04-29_10-Q\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1044046it [00:06, 158703.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 2015-02-17_10-K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2475140it [00:33, 73912.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 2014-07-25_10-Q\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "456614it [00:02, 160348.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 2014-11-04_10-Q\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "469797it [00:03, 147537.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 2014-04-25_10-Q\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "964979it [00:05, 163029.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 2014-02-13_10-K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2185937it [00:27, 79065.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OPTICAL CABLE CORP directory exists\n",
      "Downloading: 2018-09-11_10-Q\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "175847it [00:01, 143282.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 2018-03-13_10-Q\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163228it [00:01, 148494.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 2018-12-19_10-K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1356360it [00:08, 165298.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 2017-09-12_10-Q\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "183658it [00:01, 134052.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 2018-06-11_10-Q\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "183227it [00:01, 132840.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 2017-12-20_10-K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "707192it [00:04, 147053.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 2017-06-13_10-Q\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "188605it [00:06, 28133.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 2016-12-20_10-K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "662329it [00:04, 146756.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 2017-03-08_10-Q\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "179353it [00:10, 16338.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 2016-09-13_10-Q\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192002it [00:01, 103801.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 2016-06-07_10-Q\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "194482it [00:05, 32851.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 2015-09-11_10-Q\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200584it [00:01, 119514.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 2016-01-28_10-K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "586403it [00:11, 50032.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 2016-03-14_10-Q\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180356it [00:01, 129553.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 2015-06-12_10-Q\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "260052it [00:02, 92613.03it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 2015-03-10_10-Q\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "247231it [00:01, 129932.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 2014-09-10_10-Q\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "264875it [00:03, 72702.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 2014-12-19_10-K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1280940it [00:18, 68957.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 2014-06-11_10-Q\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "258902it [00:04, 58803.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 2014-03-17_10-Q\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "268249it [00:04, 64252.13it/s]\n"
     ]
    }
   ],
   "source": [
    "download_filings([1000045, 1000229, 1000230])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
